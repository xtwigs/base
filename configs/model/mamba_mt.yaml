_target_: src.models.mamba.mamba_mt.MambaMT
is_encoder_decoder: false
d_model: 610
n_layer: 24
rms_norm: true
fused_add_norm: true
use_fast_path: false
vocab_size: ${experiment.vocab_size}
learning_rate: 1e-3
warmup_steps: 1000

dropout: ${experiment.dropout}
precision: bf16-mixed

optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: 1e-3
  weight_decay: 0.001





